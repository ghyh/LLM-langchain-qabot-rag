{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a20621-ee9e-4343-8cba-0e24d9629c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://python.langchain.com/docs/tutorials/chatbot/\n",
    "# Monitor and evaluate an LLM application using LangSmith\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(prompt=\"LangChain API Key: \")\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"{PROJECT_NAME}\"\n",
    "\n",
    "# Ref: https://python.langchain.com/docs/tutorials/rag/\n",
    "# Ref: https://www.educative.io/blog/ollama-guide\n",
    "# Ref: https://community.deeplearning.ai/t/try-filtering-complex-metadata-from-the-document-using-langchain-community-vectorstores-utils-filter-complex-metadata/628474/2\n",
    "# Using Chroma as the vector store\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "embeddings=OllamaEmbeddings(model=\"tinyllama\");\n",
    "vector_store = Chroma(embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4d79f8-ace1-42ce-a7eb-f0f5f88eb5f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ref: https://python.langchain.com/docs/integrations/chat/ollama/\n",
    "# Ref: https://python.langchain.com/docs/how_to/sequence/\n",
    "# Ref: https://github.com/REZ3LIET/personal_chatbot/blob/main/Scripts/qa_chatbot.py\n",
    "# Ref: https://medium.com/@ankit_data_scientist/end-to-end-creation-and-deployment-of-chatbot-with-ollama-langchain-langserve-and-langsmith-5b2f6f500c37\n",
    "# Ref: https://python.langchain.com/docs/tutorials/rag/\n",
    "# Ref: https://github.com/langchain-ai/langchain/issues/4838\n",
    "# Ref: https://python.langchain.com/docs/integrations/document_loaders/browserbase/\n",
    "# Ref: https://python.langchain.com/docs/integrations/document_loaders/firecrawl/\n",
    "# Ref: https://python.langchain.com/api_reference/unstructured/document_loaders/langchain_unstructured.document_loaders.UnstructuredLoader.html\n",
    "\n",
    "import bs4\n",
    "from langchain_community.document_loaders.firecrawl import FireCrawlLoader\n",
    "#from langchain_unstructured import UnstructuredLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# load content on the page \n",
    "WEB_PATH = \"https://en.wikipedia.org/wiki/Baseball\"\n",
    "FIRECRAWL_API_KEY = \"{FIRECRAWL_API_KEY}\"\n",
    "web_loader = FireCrawlLoader(\n",
    "    api_key=FIRECRAWL_API_KEY, url=WEB_PATH, mode=\"scrape\"\n",
    ")\n",
    "web_docs = web_loader.load()\n",
    "\n",
    "# split text into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "split_web_docs = text_splitter.split_documents(web_docs)\n",
    "chunk_index = vector_store.add_documents(documents=filter_complex_metadata(split_web_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54245d33-4238-4916-b1b7-a738f3cadf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile graph.py\n",
    "# Define state (data structure) for the RAG application, which consists of question, context, and answer\n",
    "# Ref: https://python.langchain.com/docs/tutorials/rag/\n",
    "# Ref: https://langchain-ai.github.io/langgraph/concepts/low_level/#graphs\n",
    "# Ref: https://www.getzep.com/ai-agents/langgraph-tutorial\n",
    "# Ref: https://mlflow.org/blog/langgraph-model-from-code\n",
    "# Ref: https://python.langchain.com/v0.2/docs/tutorials/rag/\n",
    "# Ref: https://python.langchain.com/docs/integrations/chat/ollama/\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langchain_core.documents import Document\n",
    "import mlflow\n",
    "from langchain import hub\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "def build_graph(vector_store) -> CompiledStateGraph:\n",
    "    # Instantiation of model using Ollama\n",
    "    llm = ChatOllama(\n",
    "        model=\"tinyllama\",\n",
    "        temperatute=0\n",
    "    )\n",
    "\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "    \n",
    "    class State(TypedDict):\n",
    "        question: str\n",
    "        context: List[Document]\n",
    "        answer: str\n",
    "\n",
    "# Define retrieval step\n",
    "# Ref: https://python.langchain.com/docs/tutorials/rag/\n",
    "\n",
    "    def retrieve(state: State):\n",
    "        retrieved_info = vector_store.similarity_search(state[\"question\"])\n",
    "        return {\"context\": retrieved_info}\n",
    "\n",
    "# Define generate step\n",
    "# Ref: https://python.langchain.com/docs/tutorials/rag/\n",
    "    def generate(state: State):\n",
    "        context_content = \"\\n\\n\".join(ext_doc.page_content for ext_doc in state[\"context\"])\n",
    "        ext_messages = prompt.invoke({\"question\": state[\"question\"],\"context\": context_content})\n",
    "        response = llm.invoke(ext_messages)\n",
    "        return {\"answer\": response.content}\n",
    "    \n",
    "# Using LangGraph to implement an application, consisting of retrieval and generation steps\n",
    "# Ref: https://www.getzep.com/ai-agents/langgraph-tutorial\n",
    "# Ref: https://python.langchain.com/docs/tutorials/rag/\n",
    "\n",
    "    graph_builder = StateGraph(State).add_sequence([retrieve,generate])\n",
    "    graph_builder.add_edge(START,\"retrieve\")\n",
    "    graph = graph_builder.compile()\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a114cf7-30d9-43d0-b84c-f70fe3b275c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from graph import build_graph\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "\n",
    "mlflow.models.set_model(build_graph(vector_store))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11becdf-0e19-4e60-a3cb-bc7d4deea992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using MLFlow to track \n",
    "# Ref: https://mlflow.org/docs/latest/getting-started/running-notebooks/index.html\n",
    "# Ref: https://python.langchain.com/docs/integrations/providers/mlflow_tracking/\n",
    "# Ref: https://mlflow.org/docs/latest/getting-started/intro-quickstart/index.html\n",
    "# Ref: https://mlflow.org/docs/latest/llms/langchain/guide/index.html\n",
    "# Ref: https://mlflow.org/docs/latest/llms/langchain/notebooks/langchain-retriever.html\n",
    "# Ref: https://mlflow.org/blog/langgraph-model-from-code\n",
    "import mlflow\n",
    "from graph import build_graph\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8081\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.langchain.log_model(\n",
    "        lc_model=\"graph.py\",\n",
    "        artifact_path=\"chatbot_rag\"\n",
    "    )\n",
    "    model_uri=model_info.model_uri\n",
    "\n",
    "# Enable tracing\n",
    "mlflow.set_experiment(\"{EXPERIMENT_NAME}\")\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "# Load the model\n",
    "loaded_mlflow_model = mlflow.langchain.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270074e7-6443-4451-a31a-1ab4f77d3423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ref: https://python.langchain.com/v0.2/docs/tutorials/rag/\n",
    "\n",
    "user_question = input(\"Enter your question about baseball: \")\n",
    "payload = {\"question\": user_question}\n",
    "response = loaded_mlflow_model.invoke(payload)\n",
    "print(f'Answer: {response.get(\"answer\")}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c512f-c7f9-4e6a-acae-e856b72510d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the database\n",
    "#vector_store.delete_collection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
