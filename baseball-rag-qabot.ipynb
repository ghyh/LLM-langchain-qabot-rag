{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a20621-ee9e-4343-8cba-0e24d9629c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "LangChain API Key:  ········\n"
     ]
    }
   ],
   "source": [
    "# Ref: https://python.langchain.com/docs/tutorials/chatbot/\n",
    "# Monitor and evaluate an LLM application using LangSmith\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(prompt=\"LangChain API Key: \")\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"{PROJECT_NAME}\"\n",
    "\n",
    "# Ref: https://python.langchain.com/docs/tutorials/rag/\n",
    "# Ref: https://www.educative.io/blog/ollama-guide\n",
    "# Ref: https://community.deeplearning.ai/t/try-filtering-complex-metadata-from-the-document-using-langchain-community-vectorstores-utils-filter-complex-metadata/628474/2\n",
    "# Using Chroma as the vector store\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "embeddings=OllamaEmbeddings(model=\"tinyllama\");\n",
    "vector_store = Chroma(embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4d79f8-ace1-42ce-a7eb-f0f5f88eb5f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ref: https://python.langchain.com/docs/integrations/chat/ollama/\n",
    "# Ref: https://python.langchain.com/docs/how_to/sequence/\n",
    "# Ref: https://github.com/REZ3LIET/personal_chatbot/blob/main/Scripts/qa_chatbot.py\n",
    "# Ref: https://medium.com/@ankit_data_scientist/end-to-end-creation-and-deployment-of-chatbot-with-ollama-langchain-langserve-and-langsmith-5b2f6f500c37\n",
    "# Ref: https://python.langchain.com/docs/tutorials/rag/\n",
    "# Ref: https://github.com/langchain-ai/langchain/issues/4838\n",
    "# Ref: https://python.langchain.com/docs/integrations/document_loaders/browserbase/\n",
    "# Ref: https://python.langchain.com/docs/integrations/document_loaders/firecrawl/\n",
    "# Ref: https://python.langchain.com/api_reference/unstructured/document_loaders/langchain_unstructured.document_loaders.UnstructuredLoader.html\n",
    "\n",
    "import bs4\n",
    "from langchain_community.document_loaders.firecrawl import FireCrawlLoader\n",
    "#from langchain_unstructured import UnstructuredLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# load content on the page \n",
    "WEB_PATH = \"https://en.wikipedia.org/wiki/Baseball\"\n",
    "FIRECRAWL_API_KEY = \"{FIRECRAWL_API_KEY}\"\n",
    "web_loader = FireCrawlLoader(\n",
    "    api_key=FIRECRAWL_API_KEY, url=WEB_PATH, mode=\"scrape\"\n",
    ")\n",
    "web_docs = web_loader.load()\n",
    "\n",
    "# split text into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "split_web_docs = text_splitter.split_documents(web_docs)\n",
    "chunk_index = vector_store.add_documents(documents=filter_complex_metadata(split_web_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54245d33-4238-4916-b1b7-a738f3cadf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting graph.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile graph.py\n",
    "# Define state (data structure) for the RAG application, which consists of question, context, and answer\n",
    "# Ref: https://python.langchain.com/docs/tutorials/rag/\n",
    "# Ref: https://langchain-ai.github.io/langgraph/concepts/low_level/#graphs\n",
    "# Ref: https://www.getzep.com/ai-agents/langgraph-tutorial\n",
    "# Ref: https://mlflow.org/blog/langgraph-model-from-code\n",
    "# Ref: https://python.langchain.com/v0.2/docs/tutorials/rag/\n",
    "# Ref: https://python.langchain.com/docs/integrations/chat/ollama/\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langchain_core.documents import Document\n",
    "import mlflow\n",
    "from langchain import hub\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "def build_graph(vector_store) -> CompiledStateGraph:\n",
    "    # Instantiation of model using Ollama\n",
    "    llm = ChatOllama(\n",
    "        model=\"tinyllama\",\n",
    "        temperatute=0\n",
    "    )\n",
    "\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "    \n",
    "    class State(TypedDict):\n",
    "        question: str\n",
    "        context: List[Document]\n",
    "        answer: str\n",
    "\n",
    "# Define retrieval step\n",
    "# Ref: https://python.langchain.com/docs/tutorials/rag/\n",
    "\n",
    "    def retrieve(state: State):\n",
    "        retrieved_info = vector_store.similarity_search(state[\"question\"])\n",
    "        return {\"context\": retrieved_info}\n",
    "\n",
    "# Define generate step\n",
    "# Ref: https://python.langchain.com/docs/tutorials/rag/\n",
    "    def generate(state: State):\n",
    "        context_content = \"\\n\\n\".join(ext_doc.page_content for ext_doc in state[\"context\"])\n",
    "        ext_messages = prompt.invoke({\"question\": state[\"question\"],\"context\": context_content})\n",
    "        response = llm.invoke(ext_messages)\n",
    "        return {\"answer\": response.content}\n",
    "    \n",
    "# Using LangGraph to implement an application, consisting of retrieval and generation steps\n",
    "# Ref: https://www.getzep.com/ai-agents/langgraph-tutorial\n",
    "# Ref: https://python.langchain.com/docs/tutorials/rag/\n",
    "\n",
    "    graph_builder = StateGraph(State).add_sequence([retrieve,generate])\n",
    "    graph_builder.add_edge(START,\"retrieve\")\n",
    "    graph = graph_builder.compile()\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a114cf7-30d9-43d0-b84c-f70fe3b275c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from graph import build_graph\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "\n",
    "mlflow.models.set_model(build_graph(vector_store))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e11becdf-0e19-4e60-a3cb-bc7d4deea992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/06 02:54:57 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpz945u_yv/model, flavor: langchain). Fall back to return ['langchain==0.3.13', 'pydantic==2.10.4', 'cloudpickle==3.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\u001b[31m2025/01/06 02:54:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run dapper-dolphin-13 at: http://127.0.0.1:8081/#/experiments/0/runs/33a798dcc2af419fa50b321068e04986\n",
      "🧪 View experiment at: http://127.0.0.1:8081/#/experiments/0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39fafe57b974384bf26de7904e20b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using MLFlow to track \n",
    "# Ref: https://mlflow.org/docs/latest/getting-started/running-notebooks/index.html\n",
    "# Ref: https://python.langchain.com/docs/integrations/providers/mlflow_tracking/\n",
    "# Ref: https://mlflow.org/docs/latest/getting-started/intro-quickstart/index.html\n",
    "# Ref: https://mlflow.org/docs/latest/llms/langchain/guide/index.html\n",
    "# Ref: https://mlflow.org/docs/latest/llms/langchain/notebooks/langchain-retriever.html\n",
    "# Ref: https://mlflow.org/blog/langgraph-model-from-code\n",
    "import mlflow\n",
    "from graph import build_graph\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8081\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.langchain.log_model(\n",
    "        lc_model=\"graph.py\",\n",
    "        artifact_path=\"chatbot_rag\"\n",
    "    )\n",
    "    model_uri=model_info.model_uri\n",
    "\n",
    "# Enable tracing\n",
    "mlflow.set_experiment(\"{EXPERIMENT_NAME}\")\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "# Load the model\n",
    "loaded_mlflow_model = mlflow.langchain.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "270074e7-6443-4451-a31a-1ab4f77d3423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question about baseball:  how many strikes are needed to get a batter out?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Question: How many strikeouts are needed to get a batter out in amateur and professional play around the world?\n",
      "\n",
      "Context: Baseball's history is as deep-rooted as it is on North American and American continents. The basic fielding statistics include [runners scored per inning](/wiki/Run_per_inning \"Run per inning\") and [runners stolen per inning](/wiki/Stolen_bases_per_inning \"Runners stolen per inning\"), but there is no game clock or pace-of-play regulation.\n",
      "\n",
      "References:\n",
      "[153] (cite_note) [Pitch Clock](https://en.wikipedia.org/wiki/PiTCh_clock).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ref: https://python.langchain.com/v0.2/docs/tutorials/rag/\n",
    "\n",
    "user_question = input(\"Enter your question about baseball: \")\n",
    "payload = {\"question\": user_question}\n",
    "response = loaded_mlflow_model.invoke(payload)\n",
    "print(f'Answer: {response.get(\"answer\")}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c512f-c7f9-4e6a-acae-e856b72510d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the database\n",
    "#vector_store.delete_collection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
